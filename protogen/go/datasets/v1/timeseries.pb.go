// Timeseries types for workflows

// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.6
// 	protoc        (unknown)
// source: datasets/v1/timeseries.proto

package datasetsv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	durationpb "google.golang.org/protobuf/types/known/durationpb"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// TimeseriesDatasetChunk is a message that represents a chunk of a timeseries dataset.
// used by workflow tasks that are executed once for each datapoint in a timeseries dataset
type TimeseriesDatasetChunk struct {
	state                 protoimpl.MessageState `protogen:"open.v1"`
	DatasetId             *ID                    `protobuf:"bytes,1,opt,name=dataset_id,json=datasetId,proto3" json:"dataset_id,omitempty"`
	CollectionId          *ID                    `protobuf:"bytes,2,opt,name=collection_id,json=collectionId,proto3" json:"collection_id,omitempty"`
	TimeInterval          *TimeInterval          `protobuf:"bytes,3,opt,name=time_interval,json=timeInterval,proto3" json:"time_interval,omitempty"`
	DatapointInterval     *DatapointInterval     `protobuf:"bytes,4,opt,name=datapoint_interval,json=datapointInterval,proto3" json:"datapoint_interval,omitempty"`
	BranchFactor          int32                  `protobuf:"varint,5,opt,name=branch_factor,json=branchFactor,proto3" json:"branch_factor,omitempty"`
	ChunkSize             int32                  `protobuf:"varint,6,opt,name=chunk_size,json=chunkSize,proto3" json:"chunk_size,omitempty"`
	DatapointsPer_365Days int64                  `protobuf:"varint,7,opt,name=datapoints_per_365_days,json=datapointsPer365Days,proto3" json:"datapoints_per_365_days,omitempty"`
	unknownFields         protoimpl.UnknownFields
	sizeCache             protoimpl.SizeCache
}

func (x *TimeseriesDatasetChunk) Reset() {
	*x = TimeseriesDatasetChunk{}
	mi := &file_datasets_v1_timeseries_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TimeseriesDatasetChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TimeseriesDatasetChunk) ProtoMessage() {}

func (x *TimeseriesDatasetChunk) ProtoReflect() protoreflect.Message {
	mi := &file_datasets_v1_timeseries_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TimeseriesDatasetChunk.ProtoReflect.Descriptor instead.
func (*TimeseriesDatasetChunk) Descriptor() ([]byte, []int) {
	return file_datasets_v1_timeseries_proto_rawDescGZIP(), []int{0}
}

func (x *TimeseriesDatasetChunk) GetDatasetId() *ID {
	if x != nil {
		return x.DatasetId
	}
	return nil
}

func (x *TimeseriesDatasetChunk) GetCollectionId() *ID {
	if x != nil {
		return x.CollectionId
	}
	return nil
}

func (x *TimeseriesDatasetChunk) GetTimeInterval() *TimeInterval {
	if x != nil {
		return x.TimeInterval
	}
	return nil
}

func (x *TimeseriesDatasetChunk) GetDatapointInterval() *DatapointInterval {
	if x != nil {
		return x.DatapointInterval
	}
	return nil
}

func (x *TimeseriesDatasetChunk) GetBranchFactor() int32 {
	if x != nil {
		return x.BranchFactor
	}
	return 0
}

func (x *TimeseriesDatasetChunk) GetChunkSize() int32 {
	if x != nil {
		return x.ChunkSize
	}
	return 0
}

func (x *TimeseriesDatasetChunk) GetDatapointsPer_365Days() int64 {
	if x != nil {
		return x.DatapointsPer_365Days
	}
	return 0
}

// TimeChunk is a message that represents a time interval and a chunk size.
// used by workflow tasks that are executed once for each chunk of size chunk_size in a time interval
// e.g. for a time interval of 100 days, and a chunk size of 1 day, such a workflow will spawn a tree of
// eventually 100 leaf tasks
type TimeChunk struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	TimeInterval  *TimeInterval          `protobuf:"bytes,1,opt,name=time_interval,json=timeInterval,proto3" json:"time_interval,omitempty"`
	ChunkSize     *durationpb.Duration   `protobuf:"bytes,2,opt,name=chunk_size,json=chunkSize,proto3" json:"chunk_size,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *TimeChunk) Reset() {
	*x = TimeChunk{}
	mi := &file_datasets_v1_timeseries_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *TimeChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*TimeChunk) ProtoMessage() {}

func (x *TimeChunk) ProtoReflect() protoreflect.Message {
	mi := &file_datasets_v1_timeseries_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use TimeChunk.ProtoReflect.Descriptor instead.
func (*TimeChunk) Descriptor() ([]byte, []int) {
	return file_datasets_v1_timeseries_proto_rawDescGZIP(), []int{1}
}

func (x *TimeChunk) GetTimeInterval() *TimeInterval {
	if x != nil {
		return x.TimeInterval
	}
	return nil
}

func (x *TimeChunk) GetChunkSize() *durationpb.Duration {
	if x != nil {
		return x.ChunkSize
	}
	return nil
}

var File_datasets_v1_timeseries_proto protoreflect.FileDescriptor

const file_datasets_v1_timeseries_proto_rawDesc = "" +
	"\n" +
	"\x1cdatasets/v1/timeseries.proto\x12\vdatasets.v1\x1a\x16datasets/v1/core.proto\x1a\x1egoogle/protobuf/duration.proto\"\x88\x03\n" +
	"\x16TimeseriesDatasetChunk\x12.\n" +
	"\n" +
	"dataset_id\x18\x01 \x01(\v2\x0f.datasets.v1.IDR\tdatasetId\x124\n" +
	"\rcollection_id\x18\x02 \x01(\v2\x0f.datasets.v1.IDR\fcollectionId\x12>\n" +
	"\rtime_interval\x18\x03 \x01(\v2\x19.datasets.v1.TimeIntervalR\ftimeInterval\x12M\n" +
	"\x12datapoint_interval\x18\x04 \x01(\v2\x1e.datasets.v1.DatapointIntervalR\x11datapointInterval\x12#\n" +
	"\rbranch_factor\x18\x05 \x01(\x05R\fbranchFactor\x12\x1d\n" +
	"\n" +
	"chunk_size\x18\x06 \x01(\x05R\tchunkSize\x125\n" +
	"\x17datapoints_per_365_days\x18\a \x01(\x03R\x14datapointsPer365Days\"\x85\x01\n" +
	"\tTimeChunk\x12>\n" +
	"\rtime_interval\x18\x01 \x01(\v2\x19.datasets.v1.TimeIntervalR\ftimeInterval\x128\n" +
	"\n" +
	"chunk_size\x18\x02 \x01(\v2\x19.google.protobuf.DurationR\tchunkSizeB\xb1\x01\n" +
	"\x0fcom.datasets.v1B\x0fTimeseriesProtoP\x01Z@github.com/tilebox/tilebox-go/protogen/go/datasets/v1;datasetsv1\xa2\x02\x03DXX\xaa\x02\vDatasets.V1\xca\x02\vDatasets\\V1\xe2\x02\x17Datasets\\V1\\GPBMetadata\xea\x02\fDatasets::V1b\x06proto3"

var (
	file_datasets_v1_timeseries_proto_rawDescOnce sync.Once
	file_datasets_v1_timeseries_proto_rawDescData []byte
)

func file_datasets_v1_timeseries_proto_rawDescGZIP() []byte {
	file_datasets_v1_timeseries_proto_rawDescOnce.Do(func() {
		file_datasets_v1_timeseries_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_datasets_v1_timeseries_proto_rawDesc), len(file_datasets_v1_timeseries_proto_rawDesc)))
	})
	return file_datasets_v1_timeseries_proto_rawDescData
}

var file_datasets_v1_timeseries_proto_msgTypes = make([]protoimpl.MessageInfo, 2)
var file_datasets_v1_timeseries_proto_goTypes = []any{
	(*TimeseriesDatasetChunk)(nil), // 0: datasets.v1.TimeseriesDatasetChunk
	(*TimeChunk)(nil),              // 1: datasets.v1.TimeChunk
	(*ID)(nil),                     // 2: datasets.v1.ID
	(*TimeInterval)(nil),           // 3: datasets.v1.TimeInterval
	(*DatapointInterval)(nil),      // 4: datasets.v1.DatapointInterval
	(*durationpb.Duration)(nil),    // 5: google.protobuf.Duration
}
var file_datasets_v1_timeseries_proto_depIdxs = []int32{
	2, // 0: datasets.v1.TimeseriesDatasetChunk.dataset_id:type_name -> datasets.v1.ID
	2, // 1: datasets.v1.TimeseriesDatasetChunk.collection_id:type_name -> datasets.v1.ID
	3, // 2: datasets.v1.TimeseriesDatasetChunk.time_interval:type_name -> datasets.v1.TimeInterval
	4, // 3: datasets.v1.TimeseriesDatasetChunk.datapoint_interval:type_name -> datasets.v1.DatapointInterval
	3, // 4: datasets.v1.TimeChunk.time_interval:type_name -> datasets.v1.TimeInterval
	5, // 5: datasets.v1.TimeChunk.chunk_size:type_name -> google.protobuf.Duration
	6, // [6:6] is the sub-list for method output_type
	6, // [6:6] is the sub-list for method input_type
	6, // [6:6] is the sub-list for extension type_name
	6, // [6:6] is the sub-list for extension extendee
	0, // [0:6] is the sub-list for field type_name
}

func init() { file_datasets_v1_timeseries_proto_init() }
func file_datasets_v1_timeseries_proto_init() {
	if File_datasets_v1_timeseries_proto != nil {
		return
	}
	file_datasets_v1_core_proto_init()
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_datasets_v1_timeseries_proto_rawDesc), len(file_datasets_v1_timeseries_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   2,
			NumExtensions: 0,
			NumServices:   0,
		},
		GoTypes:           file_datasets_v1_timeseries_proto_goTypes,
		DependencyIndexes: file_datasets_v1_timeseries_proto_depIdxs,
		MessageInfos:      file_datasets_v1_timeseries_proto_msgTypes,
	}.Build()
	File_datasets_v1_timeseries_proto = out.File
	file_datasets_v1_timeseries_proto_goTypes = nil
	file_datasets_v1_timeseries_proto_depIdxs = nil
}
